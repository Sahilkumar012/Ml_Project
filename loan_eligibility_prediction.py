# -*- coding: utf-8 -*-
"""Loan_Eligibility_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RjfvWWWfqxyw3_1kDJVbPoTqD5AITbco

Loan Eligibility Prediction Using ML
"""

import pandas as pd

data = pd.read_csv('loan_prediction.csv')

"""### COLUMN DETAILS

###### Loan_ID : Unique Loan ID

###### Gender : Male/ Female

###### Married : Applicant married (Y/N)

###### Dependents : Number of dependents

###### Education : Applicant Education (Graduate/ Under Graduate)

###### Self_Employed : Self employed (Y/N)

###### ApplicantIncome : Applicant income

###### CoapplicantIncome : Coapplicant income

###### LoanAmount : Loan amount in thousands of dollars

###### Loan_Amount_Term : Term of loan in months

###### Credit_History : Credit history meets guidelines yes or no

###### Property_Area : Urban/ Semi Urban/ Rural

###### Loan_Status : Loan approved (Y/N) this is the target variable
"""

data.head()

data.tail()

data.shape

print("Number of Rows: ",data.shape[0])
print("Number of Columns: ",data.shape[1])

data.info()

data.isnull().sum()

data.isnull().sum()*100 / len(data)

data = data.drop('Loan_ID' , axis=1)

data.head(2)

# making a list of columns with missing percentage < 5%

columns = ['Gender','Dependents','LoanAmount','Loan_Amount_Term']

data = data.dropna(subset=columns)

data.isnull().sum()*100 / len(data)

"""All columns, except **'Self_Employed'** and **'Credit_History'** are handled and these column's missing percentage is more than 5%, so we can't delete row them, we've to fill the missing values with appropriate values."""

data['Self_Employed'].unique()

data['Credit_History'].unique()

data['Self_Employed'].mode()[0]

data['Credit_History'].mode()[0]

data['Self_Employed'] = data['Self_Employed'].fillna(data['Self_Employed'].mode()[0])

data['Credit_History'] = data['Credit_History'].fillna(data['Credit_History'].mode()[0])

data.isnull().sum()*100/len(data)

"""- All Missing Values are Handled"""

data.sample(5)

data['Dependents'].unique()

#replace 3+ with 3
data['Dependents'] = data['Dependents'].replace(to_replace="3+",value='3')

data['Loan_Status'].unique()

"""#### Encoding
As machines only understand 0's and 1's. We've to convert our categorical columns to 0's and 1's.
"""

data['Gender'] = data['Gender'].map({'Male':1,'Female':0}).astype('int')
data['Married'] = data['Married'].map({'Yes':1,'No':0}).astype('int')
data['Education'] = data['Education'].map({'Graduate':1,'Not Graduate':0}).astype('int')
data['Self_Employed'] = data['Self_Employed'].map({'Yes':1,'No':0}).astype('int')
data['Property_Area'] = data['Property_Area'].map({'Rural':0,'Semiurban':2,'Urban':1}).astype('int')
data['Loan_Status'] = data['Loan_Status'].map({'Y':1,'N':0}).astype('int')

data.head()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import svm

# Percentage of people of take loan by Gender

print("number of people who take loan as group by gender:")
print(data['Gender'].value_counts())

sns.countplot(x='Gender', data = data, palette = 'Set1')

# Percentage of people of take loan by Marital Status

print("number of people who take loan as group by marital status:")
print(data['Married'].value_counts())

sns.countplot(x='Married', data = data, palette = 'Set1')

# Percentage of people of take loan by Dependents

print("number of people who take loan as group by dependents:")
print(data['Dependents'].value_counts())

sns.countplot(x='Dependents', data = data, palette = 'Set1')

# Percentage of people of take loan by Self_Employed

print("number of people who take loan as group by Self Employed:")
print(data['Self_Employed'].value_counts())

sns.countplot(x='Self_Employed', data = data, palette = 'Set1')

# Percentage of people of take loan by Loan_Amount

print("number of people who take loan as group by Loan Amount:")
print(data['LoanAmount'].value_counts())

sns.countplot(x='LoanAmount', data = data, palette = 'Set1')

# Percentage of people of take loan by Credit History

print("number of people who take loan as group by Credit History:")
print(data['Credit_History'].value_counts())

sns.countplot(x='Credit_History', data = data, palette = 'Set1')

X = data.drop('Loan_Status', axis=1)

y = data['Loan_Status']

X

y

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score

model_df = {}

def model_val(model,X,y):
    # spliting dataset for training and testing
    X_train,X_test,y_train,y_test = train_test_split(X,y,
                                                   test_size=0.20,
                                                   random_state=42)

    # training the model
    model.fit(X_train, y_train)

    # asking model for prediction
    y_pred = model.predict(X_test)

    # checking model's prediction accuracy
    print(f"{model} accuracy is {accuracy_score(y_test,y_pred)}")

    # to find the best model we use cross-validation, thru this we can compare different algorithms
    # In this we use whole dataset to for testing not just 20%, but one at a time and summarize
    # the result at the end.

    # 5-fold cross-validation (but 10-fold cross-validation is common in practise)
    score = cross_val_score(model,X,y,cv=5)  # it will divides the dataset into 5 parts and during each iteration
                                             # uses (4,1) combination for training and testing

    print(f"{model} Avg cross val score is {np.mean(score)}")
    model_df[model] = round(np.mean(score)*100,2)

"""### Logistic Regression

"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

# passing this model object of LogisticRegression Class in the function we've created
model_val(model,X,y)

model_df

"""### Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model_val(model,X,y)

model_df

"""### SVC (Support Vector Classifier)"""

from sklearn import svm

model = svm.SVC()
model_val(model,X,y)

model_df

"""### Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

model =RandomForestClassifier()
model_val(model,X,y)

model_df

import pandas as pd

df = pd.DataFrame({
    'Gender':1,
    'Married':1,
    'Dependents':2,
    'Education':1,
    'Self_Employed':1,
    'ApplicantIncome':2889,
    'CoapplicantIncome':4187.0,
    'LoanAmount':267.0,
    'Loan_Amount_Term':160,
    'Credit_History':1,
    'Property_Area':0
},index=[0])

result = model.predict(df)

if result==1:
    print("Loan Approved")
else:
    print("Loan Not Approved")

import joblib

# Assuming 'model' is your trained model object (e.g., RandomForestClassifier)

# Specify the filename where you want to save the model
filename = 'model.sav'

# Save the model to .sav file
joblib.dump(model, filename)

for Column in df.columns :
  print (Column)

# Check numpy version using pip show
!pip show numpy

# Import pandas and print its version
import pandas
print(pandas.__version__)

# List all installed packages and grep for tensorflow
!pip freeze | grep tensorflow

# Capture pip freeze output in a variable
output = !pip freeze

# Print each line of output
for line in output:
    print(line)